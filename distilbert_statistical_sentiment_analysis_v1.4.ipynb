{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Orefle2003/AnswerTime-MetricNLP/blob/model-experiments-1/distilbert_statistical_sentiment_analysis_v1.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy transformers torch\n",
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n"
      ],
      "metadata": {
        "id": "5PYJIXS_RhBb",
        "outputId": "aa245337-2fdc-4601-88f9-bf8f6f795f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3sksucnHiO",
        "outputId": "ade2fe12-53b4-4520-dc08-fbeea6b23c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
            "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 1.0/14.9 MB 5.0 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 2.1/14.9 MB 5.1 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 2.6/14.9 MB 4.7 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 3.4/14.9 MB 4.3 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 4.5/14.9 MB 4.5 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 5.5/14.9 MB 4.6 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 6.6/14.9 MB 4.7 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 7.6/14.9 MB 4.7 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 8.7/14.9 MB 4.8 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 9.7/14.9 MB 4.8 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 10.7/14.9 MB 4.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 11.8/14.9 MB 4.8 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 12.8/14.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 13.9/14.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.7/14.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.9/14.9 MB 4.8 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'D:\\Documents\\0-MindwareAI Business Docs\\SVG Converter\\env\\Lib\\site-packages\\~-mpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'D:\\Documents\\0-MindwareAI Business Docs\\SVG Converter\\env\\Lib\\site-packages\\~-mpy'.\n",
            "  You can safely remove it manually.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "\n",
        "Basic NLP Distil-Bert model using \"finetuned-sst-2-english\" finetuning with NER (Named Entity Recognition) to calculate rudimentary sentiment distribution"
      ],
      "metadata": {
        "id": "KXGU4CpHpvVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy model for Named Entity Recognition\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Load a fine-tuned sentiment analysis model for better predictions\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
        "\n",
        "# Load a slightly larger sample of the Yelp reviews dataset for testing\n",
        "dataset = load_dataset(\"yelp_polarity\", split=\"test[:200]\")  # Increased dataset size to 200 reviews\n",
        "reviews = pd.DataFrame(dataset)\n",
        "documents = reviews['text'].tolist()\n",
        "\n",
        "# Function to truncate long documents to the maximum length of 512 tokens\n",
        "def truncate_document(doc, max_length=512):\n",
        "    return ' '.join(doc.split()[:max_length])\n",
        "\n",
        "# Apply truncation to all documents to ensure they are within the model's limit\n",
        "truncated_documents = [truncate_document(doc) for doc in documents]\n",
        "\n",
        "# Function to extract relevant entities (e.g., restaurant names)\n",
        "def extract_relevant_entities(documents):\n",
        "    entities = set()\n",
        "    for doc in documents:\n",
        "        spacy_doc = nlp(doc)\n",
        "        for ent in spacy_doc.ents:\n",
        "            # Only include entities such as organizations, places, etc.\n",
        "            if ent.label_ in ['ORG', 'GPE', 'LOC']:\n",
        "                entities.add(ent.text.lower())\n",
        "    return entities\n",
        "\n",
        "# Extract entities from the documents\n",
        "relevant_entities = extract_relevant_entities(truncated_documents)\n",
        "print(\"\\nExtracted Entities:\", relevant_entities)\n",
        "\n",
        "# Function to analyze sentiment for each entity\n",
        "def analyze_entity_sentiment(documents, entities):\n",
        "    entity_sentiment_counts = defaultdict(lambda: {'positive': 0, 'negative': 0, 'neutral': 0, 'total': 0})\n",
        "\n",
        "    for doc in documents:\n",
        "        for entity in entities:\n",
        "            if entity in doc.lower():  # Check if the entity is mentioned in the document\n",
        "                sentiment = sentiment_model(doc[:512])  # Truncate to model's max input size\n",
        "                label = sentiment[0]['label']\n",
        "                entity_sentiment_counts[entity]['total'] += 1\n",
        "                if label == 'POSITIVE':\n",
        "                    entity_sentiment_counts[entity]['positive'] += 1\n",
        "                elif label == 'NEGATIVE':\n",
        "                    entity_sentiment_counts[entity]['negative'] += 1\n",
        "                else:\n",
        "                    entity_sentiment_counts[entity]['neutral'] += 1\n",
        "\n",
        "    # Calculate and print the percentage of positive mentions for each entity\n",
        "    for entity, counts in entity_sentiment_counts.items():\n",
        "        if counts['total'] > 0:\n",
        "            positive_pct = (counts['positive'] / counts['total']) * 100\n",
        "            print(f\"{positive_pct:.2f}% of reviewers mentioned '{entity}' positively out of {counts['total']} mentions.\")\n",
        "        else:\n",
        "            print(f\"No mentions of '{entity}' found.\")\n",
        "\n",
        "# Run the sentiment analysis function\n",
        "analyze_entity_sentiment(truncated_documents, relevant_entities)\n"
      ],
      "metadata": {
        "id": "9dMLPWoYRoNd",
        "outputId": "93273bd7-dc80-488b-9e09-a3798dbf161f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted Entities: {'pennsylvania', \"max's allegheny tavern\", 'the port authority', 'california', 'seattle', 'soho', 'totally', 'funds availability policy', 'ct', 'hmmmmm', \"men's\", 'the original fish market', 'the pittsburgh international airport', 'shopping.\\\\n\\\\nwe', 'the cultural district', \"the people's special biryani\", 'new haven', 'waterfront', 'penzeys', 'shadyside', 'crab & tomato', 'dairy queen', 'reyna foods', 'san diego', 'oakland', 'betos', 'izzazu', 'imho', 'the red alert', 'blues', 'mcn', 'ktm', 'nyc', 'rock bottom brewery', 'tomaso', 'front desk staff', 'port authority', 'piggy', 'un-clean', 'carnegie mellon university', 'mxc', '2011.\\\\n\\\\nthe university of pittsburgh', 'd&b', 'atm', 'awhile ago &', 'potato gnocchi', 'byob', 'olive garden', 'brighton heights', 'pgh', 'zero', 'dq', 'yelp', 'squirrel hill', 'the fish sandwich &', 'oclv', 'primanti', 'lol', 'us', 'korean bbq sauce &', 'steeler', 'koh samui thailand', 'immediately', 'hint', 'caramel', 'la prima', '\\\\\"\"special\\\\', '\\\\\"\"we', 'curly schnitzel', \"little caesar's\", 'getaway', 'page', 'ravioli & salmon', 'pittsburgh &', 'wmata', 'caribbean', 'the renaissance hotel', '\\\\\"\"bill\\'s burgers &', 'crab & lots', 'sysco \\\\\"\"meat,\\\\', 'capital grille', 'vietnam', 'heinz', 'wiener schnitzel', 'tj maxx', 'tastee freeze', 'cheap', 'd.c.', 'bbb', 'ca', 'springhill', 'tram', 'the forest room', 'west view', 'really', 'portugal', 'nj', 'sea scallops & octopus and duck confit', 'mom & pop', 'the clams casino', 'schnitzel', 'smartrip', 'it.\\\\n\\\\n- broccoli', 'battleship', 'nyer', 'entree, & tiramisu', 'chicken ranch club', 'sancholi', 'monets', 'ny', 'pasta fazoo', 'funds availability', 'shut up & sing sing', 'whole foods', 'primate bros.', '\\\\\"\"miss pat\\\\\"\"--another', 'pizza hut', \"bloody mary's!\\\\n\\\\nperfect\", 'saks', 'the midwife center', 'pittsburgh', 'the strip district', 'bed', 'salisbury', 'penn mac', 'armageddon', 'big burrito', 'the old fishmarket', 'bj', 'never', 'primanti bros.', 'products--', 'dormont', 'unos', 'arl', 'lot', 'the wiener schnitzel', '\\\\\"\"i', 'pizza', 'cezannes', 'amazon', 'the smallman street fries', 'london', 'the boyd & blair', 'swissvale', 'pitt/oakland', \"oakland.\\\\n\\\\nthe port authority's\", 'bbq', 'mexico', 'macaroon', 'the north shore', 'tessaro', 'chicago', 'insipid', 'rangoon', 'the byham theatre', 'hoisin', 'fiori', 'atlanta', 'houston', 'singapore', 'buffet', 'giant eagle', 'smashing--', 'pasta', 'brgr', 'mango', 'bloomfield', 'cleveland', 'the lobster roll', 'downtown', 'lassi', 'strip', 'south hills', 'nye', 'china sea', 'pnc park', 'casbah', 'west busway', 'the harris theater', 'extra.\\\\n\\\\nhowever', 'a steel dynasty', 'pirates', 'the lemon grass cafe', 'mason', 'patransit', 'barnes & noble', 'downtown pittsburgh', 'westins', 'china express', '\\\\n\\\\ntessaro', 'wow', 'roland', 'fiore'}\n",
            "0.00% of reviewers mentioned 'zero' positively out of 4 mentions.\n",
            "51.01% of reviewers mentioned 'us' positively out of 149 mentions.\n",
            "46.92% of reviewers mentioned 'ca' positively out of 130 mentions.\n",
            "65.62% of reviewers mentioned 'lot' positively out of 32 mentions.\n",
            "38.24% of reviewers mentioned 'never' positively out of 34 mentions.\n",
            "42.86% of reviewers mentioned 'ny' positively out of 77 mentions.\n",
            "55.06% of reviewers mentioned 'ct' positively out of 89 mentions.\n",
            "66.67% of reviewers mentioned 'waterfront' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'tj maxx' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'saks' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'pittsburgh' positively out of 38 mentions.\n",
            "60.00% of reviewers mentioned 'downtown' positively out of 10 mentions.\n",
            "100.00% of reviewers mentioned 'rock bottom brewery' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'shut up & sing sing' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'd&b' positively out of 2 mentions.\n",
            "66.67% of reviewers mentioned 'really' positively out of 39 mentions.\n",
            "66.67% of reviewers mentioned 'atm' positively out of 12 mentions.\n",
            "47.06% of reviewers mentioned 'cheap' positively out of 17 mentions.\n",
            "61.11% of reviewers mentioned 'nj' positively out of 18 mentions.\n",
            "100.00% of reviewers mentioned 'amazon' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'barnes & noble' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'steeler' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'unos' positively out of 1 mentions.\n",
            "85.71% of reviewers mentioned 'pizza' positively out of 14 mentions.\n",
            "16.67% of reviewers mentioned 'immediately' positively out of 6 mentions.\n",
            "0.00% of reviewers mentioned 'singapore' positively out of 1 mentions.\n",
            "25.00% of reviewers mentioned 'hint' positively out of 4 mentions.\n",
            "40.00% of reviewers mentioned 'totally' positively out of 5 mentions.\n",
            "0.00% of reviewers mentioned 'oclv' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'bbb' positively out of 1 mentions.\n",
            "72.73% of reviewers mentioned 'strip' positively out of 11 mentions.\n",
            "0.00% of reviewers mentioned 'chicken ranch club' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'china sea' positively out of 1 mentions.\n",
            "75.00% of reviewers mentioned 'wow' positively out of 4 mentions.\n",
            "100.00% of reviewers mentioned 'dq' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'tastee freeze' positively out of 1 mentions.\n",
            "57.14% of reviewers mentioned 'arl' positively out of 21 mentions.\n",
            "50.00% of reviewers mentioned 'nyc' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned '\\\"\"we' positively out of 2 mentions.\n",
            "50.00% of reviewers mentioned '\\\"\"i' positively out of 2 mentions.\n",
            "33.33% of reviewers mentioned 'oakland' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'pitt/oakland' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'rangoon' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'pennsylvania' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'whole foods' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'the strip district' positively out of 1 mentions.\n",
            "33.33% of reviewers mentioned 'giant eagle' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'crab & tomato' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'bj' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'casbah' positively out of 4 mentions.\n",
            "100.00% of reviewers mentioned 'potato gnocchi' positively out of 1 mentions.\n",
            "75.00% of reviewers mentioned 'caramel' positively out of 4 mentions.\n",
            "100.00% of reviewers mentioned 'page' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'sea scallops & octopus and duck confit' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'big burrito' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'macaroon' positively out of 1 mentions.\n",
            "66.67% of reviewers mentioned 'nye' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'the boyd & blair' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'smashing--' positively out of 1 mentions.\n",
            "20.00% of reviewers mentioned 'bed' positively out of 5 mentions.\n",
            "0.00% of reviewers mentioned 'imho' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'san diego' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'portugal' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'shadyside' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'byob' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'hmmmmm' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'men's' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'izzazu' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'cleveland' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'dairy queen' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'funds availability policy' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'squirrel hill' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'funds availability' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'ktm' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'mxc' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'max's allegheny tavern' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'curly schnitzel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'wiener schnitzel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'schnitzel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the wiener schnitzel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'mason' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'monets' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'cezannes' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'houston' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'ravioli & salmon' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'heinz' positively out of 2 mentions.\n",
            "66.67% of reviewers mentioned 'pnc park' positively out of 3 mentions.\n",
            "66.67% of reviewers mentioned 'pasta' positively out of 6 mentions.\n",
            "50.00% of reviewers mentioned 'seattle' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'a steel dynasty' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'brighton heights' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'west view' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'california' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'mom & pop' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'betos' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'dormont' positively out of 1 mentions.\n",
            "33.33% of reviewers mentioned 'buffet' positively out of 3 mentions.\n",
            "33.33% of reviewers mentioned 'mango' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'lassi' positively out of 4 mentions.\n",
            "100.00% of reviewers mentioned 'the red alert' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'chicago' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'battleship' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'swissvale' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'olive garden' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'pasta fazoo' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'mcn' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'piggy' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'extra.\\n\\nhowever' positively out of 1 mentions.\n",
            "66.67% of reviewers mentioned 'yelp' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'products--' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'soho' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'springhill' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the original fish market' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the port authority' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the pittsburgh international airport' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'port authority' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'carnegie mellon university' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned '2011.\\n\\nthe university of pittsburgh' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'wmata' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'smartrip' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned '\\\"\"miss pat\\\"\"--another' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'london' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'oakland.\\n\\nthe port authority's' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'south hills' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'west busway' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'patransit' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'koh samui thailand' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'primate bros.' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'primanti' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'salisbury' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'primanti bros.' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the smallman street fries' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'caribbean' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'atlanta' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'nyer' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'mexico' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'reyna foods' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the lobster roll' positively out of 2 mentions.\n",
            "50.00% of reviewers mentioned 'roland' positively out of 4 mentions.\n",
            "0.00% of reviewers mentioned 'lol' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the clams casino' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'shopping.\\n\\nwe' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'penzeys' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'bloody mary's!\\n\\nperfect' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'penn mac' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'un-clean' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'awhile ago &' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'pittsburgh &' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'entree, & tiramisu' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'korean bbq sauce &' positively out of 1 mentions.\n",
            "66.67% of reviewers mentioned 'bbq' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'china express' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'la prima' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the forest room' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the midwife center' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'blues' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'capital grille' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'it.\\n\\n- broccoli' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'pirates' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'pgh' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the harris theater' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'front desk staff' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the cultural district' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the renaissance hotel' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the byham theatre' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'downtown pittsburgh' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the north shore' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'westins' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned '\\\"\"bill's burgers &' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the old fishmarket' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the fish sandwich &' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'crab & lots' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'the lemon grass cafe' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'd.c.' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the people's special biryani' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'vietnam' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'hoisin' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned '\\\"\"special\\' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'tomaso' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'tram' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'armageddon' positively out of 1 mentions.\n",
            "75.00% of reviewers mentioned 'tessaro' positively out of 4 mentions.\n",
            "0.00% of reviewers mentioned 'brgr' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'sysco \\\"\"meat,\\' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'bloomfield' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned '\\n\\ntessaro' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'sancholi' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'insipid' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'getaway' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'new haven' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'little caesar's' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'pizza hut' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'fiori' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'fiore' positively out of 1 mentions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model 2\n",
        "Entity-Aware Sentiment Analyzer (EASA)\n",
        "\n",
        "The model focuses on extracting relevant entities and analyses their sentiment."
      ],
      "metadata": {
        "id": "ZlKo5mhOwyPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy model for Named Entity Recognition\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Load a fine-tuned sentiment analysis model for better predictions\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
        "\n",
        "# Load a slightly larger sample of the Yelp reviews dataset for testing\n",
        "dataset = load_dataset(\"yelp_polarity\", split=\"test[:1000]\")  # Increased dataset size to 200 reviews\n",
        "reviews = pd.DataFrame(dataset)\n",
        "documents = reviews['text'].tolist()\n",
        "\n",
        "# Function to truncate long documents to the maximum length of 512 tokens\n",
        "def truncate_document(doc, max_length=512):\n",
        "    return ' '.join(doc.split()[:max_length])\n",
        "\n",
        "# Apply truncation to all documents to ensure they are within the model's limit\n",
        "truncated_documents = [truncate_document(doc) for doc in documents]\n",
        "\n",
        "# Function to extract relevant entities with refined filters\n",
        "def extract_relevant_entities(documents):\n",
        "    entities = defaultdict(int)  # Track entity frequencies\n",
        "    for doc in documents:\n",
        "        spacy_doc = nlp(doc)\n",
        "        for ent in spacy_doc.ents:\n",
        "            # Include only organizations (ORG), geopolitical entities (GPE), and locations (LOC)\n",
        "            if ent.label_ in ['ORG', 'GPE', 'LOC']:\n",
        "                entity_text = ent.text.strip().lower()\n",
        "                # Filter out irrelevant entities\n",
        "                if len(entity_text.split()) > 1 or entity_text.istitle():  # Allow multi-word or title-case entities\n",
        "                    entities[entity_text] += 1\n",
        "\n",
        "    # Apply additional filtering: exclude low-frequency and irrelevant entities\n",
        "    filtered_entities = {entity for entity, count in entities.items() if count > 1}  # Only keep entities mentioned > 1\n",
        "    return filtered_entities\n",
        "\n",
        "# Extract entities from the documents\n",
        "relevant_entities = extract_relevant_entities(truncated_documents)\n",
        "print(\"\\nFiltered Entities:\", relevant_entities)\n",
        "\n",
        "# Function to analyze sentiment for each entity\n",
        "def analyze_entity_sentiment(documents, entities):\n",
        "    entity_sentiment_counts = defaultdict(lambda: {'positive': 0, 'negative': 0, 'neutral': 0, 'total': 0})\n",
        "\n",
        "    for doc in documents:\n",
        "        for entity in entities:\n",
        "            if entity in doc.lower():  # Check if the entity is mentioned in the document\n",
        "                sentiment = sentiment_model(doc[:512])  # Truncate to model's max input size\n",
        "                label = sentiment[0]['label']\n",
        "                entity_sentiment_counts[entity]['total'] += 1\n",
        "                if label == 'POSITIVE':\n",
        "                    entity_sentiment_counts[entity]['positive'] += 1\n",
        "                elif label == 'NEGATIVE':\n",
        "                    entity_sentiment_counts[entity]['negative'] += 1\n",
        "                else:\n",
        "                    entity_sentiment_counts[entity]['neutral'] += 1\n",
        "\n",
        "    # Calculate and print the percentage of positive mentions for each entity\n",
        "    for entity, counts in entity_sentiment_counts.items():\n",
        "        if counts['total'] > 0:\n",
        "            positive_pct = (counts['positive'] / counts['total']) * 100\n",
        "            print(f\"{positive_pct:.2f}% of reviewers mentioned '{entity}' positively out of {counts['total']} mentions.\")\n",
        "        else:\n",
        "            print(f\"No mentions of '{entity}' found.\")\n",
        "\n",
        "# Run the sentiment analysis function\n",
        "analyze_entity_sentiment(truncated_documents, relevant_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aL6L-vVw1Er",
        "outputId": "899eedc8-f235-4f8b-d3b3-9ac55eb3189c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtered Entities: {'the home depot', 'the capital brewery', 'zimbrick vw', 'la tolteca', 'el nopalito', 'home depot', 'the phoenix zoo', 'time warner', 'port authority', 'caring hands', 'southern california', 'athenian express', 'rock bottom', 'the queen city', 'super 8', \"tully's ii\", 'university city', 'capital grille', 'cooperstown sports grill', 'time warner cable', 'us airways center', 'cracker barrel', 'taco bell', \"common ground's\", 'the us airways center', 'us airways', 'front row', 'whole foods', 'gabriel brothers', 'south hills', 'penn mac', 'hyde park', 'china palace', 'north carolina', 'thai house', 'alice springs chicken', 'big burrito', 'wiener schnitzel', 'san diego', '4th ward', 'common ground', 'the phoenix art museum', 'giant eagle', 'new york', 'the pear and gorgonzola'}\n",
            "100.00% of reviewers mentioned 'gabriel brothers' positively out of 1 mentions.\n",
            "66.67% of reviewers mentioned 'rock bottom' positively out of 3 mentions.\n",
            "66.67% of reviewers mentioned 'whole foods' positively out of 3 mentions.\n",
            "40.00% of reviewers mentioned 'giant eagle' positively out of 5 mentions.\n",
            "50.00% of reviewers mentioned 'big burrito' positively out of 2 mentions.\n",
            "33.33% of reviewers mentioned 'san diego' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'wiener schnitzel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'port authority' positively out of 1 mentions.\n",
            "66.67% of reviewers mentioned 'south hills' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'penn mac' positively out of 2 mentions.\n",
            "33.33% of reviewers mentioned 'capital grille' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'hyde park' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'china palace' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned '4th ward' positively out of 3 mentions.\n",
            "20.00% of reviewers mentioned 'time warner' positively out of 5 mentions.\n",
            "0.00% of reviewers mentioned 'time warner cable' positively out of 2 mentions.\n",
            "75.00% of reviewers mentioned 'southern california' positively out of 4 mentions.\n",
            "100.00% of reviewers mentioned 'the pear and gorgonzola' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'north carolina' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'the queen city' positively out of 2 mentions.\n",
            "71.43% of reviewers mentioned 'us airways' positively out of 7 mentions.\n",
            "100.00% of reviewers mentioned 'thai house' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'alice springs chicken' positively out of 1 mentions.\n",
            "50.00% of reviewers mentioned 'university city' positively out of 2 mentions.\n",
            "0.00% of reviewers mentioned 'new york' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'the capital brewery' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'zimbrick vw' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'the home depot' positively out of 1 mentions.\n",
            "33.33% of reviewers mentioned 'home depot' positively out of 3 mentions.\n",
            "0.00% of reviewers mentioned 'tully's ii' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'caring hands' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'taco bell' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'cracker barrel' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'common ground's' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'common ground' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'super 8' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'the phoenix art museum' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'cooperstown sports grill' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'us airways center' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'the us airways center' positively out of 1 mentions.\n",
            "0.00% of reviewers mentioned 'front row' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'athenian express' positively out of 2 mentions.\n",
            "100.00% of reviewers mentioned 'la tolteca' positively out of 3 mentions.\n",
            "100.00% of reviewers mentioned 'the phoenix zoo' positively out of 1 mentions.\n",
            "100.00% of reviewers mentioned 'el nopalito' positively out of 1 mentions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3\n",
        "\n",
        "Topic Modeling with Sentiment Mapping\n",
        "Method: Use a topic modeling library like BERTopic to extract topics discussed in the reviews and map sentiment scores to each topic.\n",
        "Goal: Provide insights such as:\n",
        "\"Topic A (service) is mentioned positively in 70% of reviews.\"\n",
        "\"Topic B (food quality) has a 40% negative sentiment.\""
      ],
      "metadata": {
        "id": "ysxHFynDy7YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Load fine-tuned sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
        "\n",
        "# Load Yelp reviews dataset\n",
        "dataset = load_dataset(\"yelp_polarity\", split=\"test[:200]\")  # Use a subset of the dataset for testing\n",
        "reviews = pd.DataFrame(dataset)\n",
        "documents = reviews['text'].tolist()\n",
        "\n",
        "# Truncate documents to fit model's token limit\n",
        "def truncate_document(doc, max_length=512):\n",
        "    return ' '.join(doc.split()[:max_length])\n",
        "\n",
        "truncated_documents = [truncate_document(doc) for doc in documents]\n",
        "\n",
        "# Generate a dynamic stop-word list based on term frequency\n",
        "from collections import Counter\n",
        "all_words = ' '.join(truncated_documents).lower().split()\n",
        "most_common_words = [word for word, _ in Counter(all_words).most_common(50)]  # Top 50 most frequent words\n",
        "dynamic_stop_words = list(set(most_common_words + list(ENGLISH_STOP_WORDS)))  # Convert to list\n",
        "\n",
        "# Generate topics using BERTopic\n",
        "vectorizer_model = CountVectorizer(stop_words=dynamic_stop_words, ngram_range=(1, 3))\n",
        "topic_model = BERTopic(vectorizer_model=vectorizer_model, nr_topics=\"auto\")  # Automatically reduce noise in topics\n",
        "topics, probs = topic_model.fit_transform(truncated_documents)\n",
        "\n",
        "# Map sentences to topics for detailed sentiment analysis\n",
        "sentences_per_topic = defaultdict(list)\n",
        "for doc, topic in zip(truncated_documents, topics):\n",
        "    if topic != -1:  # Exclude outliers\n",
        "        sentences_per_topic[topic].append(doc)\n",
        "\n",
        "# Perform sentiment analysis and aggregate scores by topic\n",
        "topic_sentiment = defaultdict(lambda: {\"positive\": 0, \"negative\": 0, \"total\": 0})\n",
        "\n",
        "for topic, sentences in sentences_per_topic.items():\n",
        "    for sentence in sentences:\n",
        "        sentiment = sentiment_model(sentence[:512])  # Truncate to model's max input size\n",
        "        label = sentiment[0]['label']\n",
        "        topic_sentiment[topic][\"total\"] += 1\n",
        "        if label == \"POSITIVE\":\n",
        "            topic_sentiment[topic][\"positive\"] += 1\n",
        "        elif label == \"NEGATIVE\":\n",
        "            topic_sentiment[topic][\"negative\"] += 1\n",
        "\n",
        "# Print insights for each topic\n",
        "for topic, sentiment in topic_sentiment.items():\n",
        "    total = sentiment[\"total\"]\n",
        "    if total > 0:\n",
        "        positive_pct = (sentiment[\"positive\"] / total) * 100\n",
        "        negative_pct = (sentiment[\"negative\"] / total) * 100\n",
        "        print(f\"Topic {topic}:\")\n",
        "        print(f\"  - Positive Sentiment: {positive_pct:.2f}%\")\n",
        "        print(f\"  - Negative Sentiment: {negative_pct:.2f}%\")\n",
        "        print(f\"  - Example Keywords: {topic_model.get_topic(topic)}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUlgnmjVzJFO",
        "outputId": "9e47ec4b-cb3a-4877-a960-2dff9c00664f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "  - Positive Sentiment: 55.17%\n",
            "  - Negative Sentiment: 44.83%\n",
            "  - Example Keywords: [('time', 0.011660498826360156), ('great', 0.010151014846837175), ('restaurant', 0.009931514282906272), ('service', 0.009089217054508936), ('got', 0.00894784924488207), ('pittsburgh', 0.008762045898978698), ('didnt', 0.008695396582672058), ('best', 0.008246705358259936), ('really', 0.007844646413896067), ('dont', 0.007775306383641421)]\n",
            "\n",
            "Topic 1:\n",
            "  - Positive Sentiment: 58.33%\n",
            "  - Negative Sentiment: 41.67%\n",
            "  - Example Keywords: [('cut', 0.04372502113793714), ('hair', 0.029751338797600876), ('said', 0.02462031972409449), ('wasnt', 0.022532779472775342), ('went', 0.018493102473054294), ('helmet', 0.01788457257315994), ('jacket', 0.01788457257315994), ('dont', 0.017132090067817372), ('ended', 0.017108257845638093), ('oh', 0.015509589846997074)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 4\n",
        "Comparison and Benchmark Analysis\n",
        "\n",
        "\n",
        "Perform comparative analysis across subsets of text to extract metrics that highlight differences in sentiment, frequency, or themes. This can provide insights into how entities, time periods, or categories compare against each other."
      ],
      "metadata": {
        "id": "8ATLlVsm3fW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "\n",
        "# Load fine-tuned sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
        "\n",
        "# Load spaCy model for Named Entity Recognition (NER)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load Yelp reviews dataset\n",
        "dataset = load_dataset(\"yelp_polarity\", split=\"test[:200]\")  # Subset for testing\n",
        "reviews = pd.DataFrame(dataset)\n",
        "documents = reviews['text'].tolist()\n",
        "\n",
        "# Function to truncate long documents to fit the model's limit\n",
        "def truncate_document(doc, max_length=512):\n",
        "    return ' '.join(doc.split()[:max_length])\n",
        "\n",
        "truncated_documents = [truncate_document(doc) for doc in documents]\n",
        "\n",
        "# Function to extract all entities and their frequency\n",
        "def extract_entities(documents):\n",
        "    entity_counts = Counter()\n",
        "    entity_context = defaultdict(list)  # Store the sentences where entities occur\n",
        "    for doc in documents:\n",
        "        spacy_doc = nlp(doc)\n",
        "        for ent in spacy_doc.ents:\n",
        "            if ent.label_ in [\"ORG\", \"GPE\"]:  # Focus on organizations and locations\n",
        "                entity_counts[ent.text.lower()] += 1\n",
        "                entity_context[ent.text.lower()].append(doc)\n",
        "    return entity_counts, entity_context\n",
        "\n",
        "# Extract entities and their contexts\n",
        "entity_counts, entity_context = extract_entities(truncated_documents)\n",
        "\n",
        "# Filter entities dynamically based on frequency (e.g., >2 mentions)\n",
        "relevant_entities = {entity: docs for entity, count in entity_counts.items() if count > 2}\n",
        "\n",
        "# Analyze sentiment for each relevant entity\n",
        "group_sentiment = defaultdict(lambda: {\"positive\": 0, \"negative\": 0, \"neutral\": 0, \"total\": 0})\n",
        "\n",
        "for entity, docs in relevant_entities.items():\n",
        "    for doc in entity_context[entity]:\n",
        "        sentiment = sentiment_model(doc[:512])  # Truncate to model's max input size\n",
        "        label = sentiment[0]['label']\n",
        "        group_sentiment[entity][\"total\"] += 1\n",
        "        if label == \"POSITIVE\":\n",
        "            group_sentiment[entity][\"positive\"] += 1\n",
        "        elif label == \"NEGATIVE\":\n",
        "            group_sentiment[entity][\"negative\"] += 1\n",
        "        else:\n",
        "            group_sentiment[entity][\"neutral\"] += 1\n",
        "\n",
        "# Print comparative insights\n",
        "for entity, sentiment in group_sentiment.items():\n",
        "    total = sentiment[\"total\"]\n",
        "    if total > 0:\n",
        "        positive_pct = (sentiment[\"positive\"] / total) * 100\n",
        "        negative_pct = (sentiment[\"negative\"] / total) * 100\n",
        "        print(f\"Entity: {entity.capitalize()}\")\n",
        "        print(f\"  - Positive Sentiment: {positive_pct:.2f}%\")\n",
        "        print(f\"  - Negative Sentiment: {negative_pct:.2f}%\")\n",
        "        print(f\"  - Total Mentions: {total}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Oloxrcu3gb1",
        "outputId": "fe27c005-f889-4622-c33a-e2bc7a349606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Waterfront\n",
            "  - Positive Sentiment: 66.67%\n",
            "  - Negative Sentiment: 33.33%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Pittsburgh\n",
            "  - Positive Sentiment: 51.16%\n",
            "  - Negative Sentiment: 48.84%\n",
            "  - Total Mentions: 43\n",
            "\n",
            "Entity: D&b\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 4\n",
            "\n",
            "Entity: Bbb\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 4\n",
            "\n",
            "Entity: Oakland\n",
            "  - Positive Sentiment: 33.33%\n",
            "  - Negative Sentiment: 66.67%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Whole foods\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 6\n",
            "\n",
            "Entity: Casbah\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 7\n",
            "\n",
            "Entity: Atm\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Wiener schnitzel\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Really\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Roland\n",
            "  - Positive Sentiment: 66.67%\n",
            "  - Negative Sentiment: 33.33%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Penn mac\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Tessaro\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4"
      ],
      "metadata": {
        "id": "hJ14-LTB9fie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np  # Correctly import NumPy\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load fine-tuned sentiment analysis model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", truncation=True)\n",
        "\n",
        "# Load spaCy model for Named Entity Recognition (NER)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load Yelp reviews dataset\n",
        "dataset = load_dataset(\"yelp_polarity\", split=\"test[:200]\")  # Subset for testing\n",
        "reviews = pd.DataFrame(dataset)\n",
        "documents = reviews['text'].tolist()\n",
        "\n",
        "# Function to truncate long documents to fit the model's limit\n",
        "def truncate_document(doc, max_length=512):\n",
        "    return ' '.join(doc.split()[:max_length])\n",
        "\n",
        "truncated_documents = [truncate_document(doc) for doc in documents]\n",
        "\n",
        "# Function to extract entities from the dataset\n",
        "def extract_entities(documents):\n",
        "    entity_context = defaultdict(list)  # Store the sentences where entities occur\n",
        "    for doc in documents:\n",
        "        spacy_doc = nlp(doc)\n",
        "        for ent in spacy_doc.ents:\n",
        "            if ent.label_ in [\"ORG\", \"GPE\"]:  # Focus on organizations and locations\n",
        "                entity_context[ent.text.lower()].append(doc)\n",
        "    return entity_context\n",
        "\n",
        "# Extract entities and their contexts\n",
        "entity_context = extract_entities(truncated_documents)\n",
        "\n",
        "# Perform sentiment analysis for each entity\n",
        "entity_sentiment = defaultdict(lambda: {\"positive\": 0, \"negative\": 0, \"neutral\": 0, \"total\": 0, \"score\": 0})\n",
        "\n",
        "for entity, docs in entity_context.items():\n",
        "    for doc in docs:\n",
        "        sentiment = sentiment_model(doc[:512])  # Truncate to model's max input size\n",
        "        label = sentiment[0]['label']\n",
        "        entity_sentiment[entity][\"total\"] += 1\n",
        "        if label == \"POSITIVE\":\n",
        "            entity_sentiment[entity][\"positive\"] += 1\n",
        "            entity_sentiment[entity][\"score\"] += 1  # Assign +1 for positive sentiment\n",
        "        elif label == \"NEGATIVE\":\n",
        "            entity_sentiment[entity][\"negative\"] += 1\n",
        "            entity_sentiment[entity][\"score\"] -= 1  # Assign -1 for negative sentiment\n",
        "\n",
        "# Calculate overall sentiment metrics for anomaly detection\n",
        "scores = [data[\"score\"] / data[\"total\"] for data in entity_sentiment.values()]\n",
        "mean_score = np.mean(scores)\n",
        "std_dev_score = np.std(scores)\n",
        "\n",
        "# Adjust z-score threshold for sensitivity\n",
        "sensitivity_threshold = 0.05  # Lower for higher sensitivity\n",
        "\n",
        "# Detect anomalies based on adjusted z-scores\n",
        "anomalies = {}\n",
        "for entity, data in entity_sentiment.items():\n",
        "    if data[\"total\"] > 1:  # Ensure sufficient data for the entity\n",
        "        entity_avg_score = data[\"score\"] / data[\"total\"]\n",
        "        z_score = (entity_avg_score - mean_score) / std_dev_score\n",
        "        if abs(z_score) > sensitivity_threshold:  # Lower threshold for higher sensitivity\n",
        "            anomalies[entity] = {\n",
        "                \"z_score\": z_score,\n",
        "                \"positive\": (data[\"positive\"] / data[\"total\"]) * 100,\n",
        "                \"negative\": (data[\"negative\"] / data[\"total\"]) * 100,\n",
        "                \"total_mentions\": data[\"total\"]\n",
        "            }\n",
        "\n",
        "# Print anomalies\n",
        "print(\"Detected Anomalies:\")\n",
        "for entity, data in anomalies.items():\n",
        "    print(f\"Entity: {entity.capitalize()}\")\n",
        "    print(f\"  - Z-Score: {data['z_score']:.2f}\")\n",
        "    print(f\"  - Positive Sentiment: {data['positive']:.2f}%\")\n",
        "    print(f\"  - Negative Sentiment: {data['negative']:.2f}%\")\n",
        "    print(f\"  - Total Mentions: {data['total_mentions']}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDLS1PlH9grZ",
        "outputId": "beb031be-fffb-49dc-bd9d-fe74f3c7c6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Anomalies:\n",
            "Entity: Pittsburgh\n",
            "  - Z-Score: -0.08\n",
            "  - Positive Sentiment: 51.16%\n",
            "  - Negative Sentiment: 48.84%\n",
            "  - Total Mentions: 43\n",
            "\n",
            "Entity: D&b\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 4\n",
            "\n",
            "Entity: Unos\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Hint\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Bbb\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 5\n",
            "\n",
            "Entity: Arl\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Whole foods\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 5\n",
            "\n",
            "Entity: Giant eagle\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Pennsylvania\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Casbah\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 7\n",
            "\n",
            "Entity: Nye\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Big burrito\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Caramel\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Byob\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Atm\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Izzazu\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Cleveland\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Page\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Ktm\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Mason\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Wiener schnitzel\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Schnitzel\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Houston\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Heinz\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Seattle\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Never\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Really\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Yelp\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Port authority\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: South hills\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Oakland\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Roland\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Penn mac\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: The midwife center\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 3\n",
            "\n",
            "Entity: Capital grille\n",
            "  - Z-Score: -1.14\n",
            "  - Positive Sentiment: 0.00%\n",
            "  - Negative Sentiment: 100.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Vietnam\n",
            "  - Z-Score: 0.93\n",
            "  - Positive Sentiment: 100.00%\n",
            "  - Negative Sentiment: 0.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Us\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n",
            "Entity: Bloomfield\n",
            "  - Z-Score: -0.10\n",
            "  - Positive Sentiment: 50.00%\n",
            "  - Negative Sentiment: 50.00%\n",
            "  - Total Mentions: 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features to Implement\n",
        "\n",
        "*   Advanced Topic Modeling\n",
        "*   Outlier Detection\n",
        "*   Reviewer Demographics Analysis\n",
        "*   Comparative Analysis\n",
        "*   Emotion Detection\n",
        "*   Word Cloud Visualization\n",
        "*   Contextual Sentiment\n",
        "*   Entity Mention Heatmaps\n",
        "*   Temporal Trends\n",
        "\n",
        "*   Statistical Co-occurrence Analysis\n",
        "*   Frequency Analysis for Common Themes\n",
        "*   Distribution of Ratings\n",
        "*   Key Phrase and Adjective Extraction\n",
        "*   Net Promoter Insights\n",
        "*   Percentages of Neutral Sentiments\n",
        "*   Correlation Between Sentiment and Length\n",
        "*   Keyword Trends\n",
        "*   Predictive Insights\n"
      ],
      "metadata": {
        "id": "M3rPT0GhubYO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}